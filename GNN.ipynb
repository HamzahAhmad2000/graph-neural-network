{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "     ---------------------------------------- 0.0/63.1 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/63.1 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/63.1 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------ ------------------------- 20.5/63.1 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------ ------------- 41.0/63.1 kB 196.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 63.1/63.1 kB 260.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: aiohttp in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from torch-geometric) (4.66.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->torch-geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.1 MB 1.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.1 MB 812.7 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.1 MB 812.7 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.1 MB 595.3 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.1 MB 762.6 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.1 MB 737.3 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.2/1.1 MB 719.7 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 833.5 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.3/1.1 MB 846.5 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.4/1.1 MB 836.4 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.4/1.1 MB 886.8 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.1 MB 873.2 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.1 MB 921.2 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.6/1.1 MB 923.3 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.1 MB 883.8 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.6/1.1 MB 868.8 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.7/1.1 MB 882.3 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.7/1.1 MB 894.3 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.8/1.1 MB 940.7 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 936.2 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 910.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.9/1.1 MB 904.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.9/1.1 MB 893.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 936.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 931.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.1 MB 896.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.1/1.1 MB 887.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 900.3 kB/s eta 0:00:00\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n",
      "Collecting flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Werkzeug>=3.1 (from flask)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from flask) (3.1.3)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\codew\\anaconda3\\envs\\nlp\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/103.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/103.0 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/103.0 kB 435.7 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 61.4/103.0 kB 469.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 103.0/103.0 kB 594.5 kB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/224.5 kB 1.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 122.9/224.5 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 143.4/224.5 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 153.6/224.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 224.5/224.5 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.3\n",
      "    Uninstalling Werkzeug-3.0.3:\n",
      "      Successfully uninstalled Werkzeug-3.0.3\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "Successfully installed Werkzeug-3.1.3 blinker-1.9.0 click-8.1.7 flask-3.1.0 itsdangerous-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "urduhack 1.1.1 requires Click~=7.1, but you have click 8.1.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install torch-geometric\n",
    "!pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n",
      "Number of nodes: 100\n",
      "Number of training edges: 179\n",
      "Number of testing edges: 45\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_synthetic_graph(num_nodes=100, edge_prob=0.05, seed=42):\n",
    "    G = nx.erdos_renyi_graph(n=num_nodes, p=edge_prob, seed=seed)\n",
    "    while not nx.is_connected(G):\n",
    "        G = nx.erdos_renyi_graph(n=num_nodes, p=edge_prob, seed=random.randint(0, 10000))\n",
    "    return G\n",
    "\n",
    "def preprocess_data(G, test_size=0.2, seed=42):\n",
    "    # Extract edges\n",
    "    edges = list(G.edges())\n",
    "    num_edges = len(edges)\n",
    "    \n",
    "    # Split edges into train and test\n",
    "    train_edges, test_edges = train_test_split(edges, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    # Create negative samples for testing\n",
    "    def is_not_edge(u, v, G):\n",
    "        return not G.has_edge(u, v) and u != v\n",
    "    \n",
    "    test_neg_edges = []\n",
    "    while len(test_neg_edges) < len(test_edges):\n",
    "        u = random.randint(0, G.number_of_nodes() - 1)\n",
    "        v = random.randint(0, G.number_of_nodes() - 1)\n",
    "        if is_not_edge(u, v, G):\n",
    "            test_neg_edges.append((u, v))\n",
    "    \n",
    "    # Convert to tensors\n",
    "    edge_index = torch.tensor(train_edges + test_edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Node features: identity matrix (one-hot encoding)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    x = torch.eye(num_nodes, dtype=torch.float)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    data.train_edges = torch.tensor(train_edges, dtype=torch.long)\n",
    "    data.test_edges = torch.tensor(test_edges, dtype=torch.long)\n",
    "    data.test_neg_edges = torch.tensor(test_neg_edges, dtype=torch.long)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate and preprocess the graph\n",
    "G = generate_synthetic_graph()\n",
    "data = preprocess_data(G)\n",
    "\n",
    "print(\"Data preprocessing completed.\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of training edges: {data.train_edges.size(0)}\")\n",
    "print(f\"Number of testing edges: {data.test_edges.size(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNN15Layer(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim):\n",
    "        super(GNN15Layer, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_features, hidden_dim))\n",
    "        for _ in range(14):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.dropout = 0.5\n",
    "        self.linear = nn.Linear(hidden_dim * 2, 1)  # For link prediction\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_pairs):\n",
    "        # z: node embeddings\n",
    "        # edge_pairs: [2, num_edges]\n",
    "        src = z[edge_pairs[0]]\n",
    "        dst = z[edge_pairs[1]]\n",
    "        return torch.sigmoid((src * dst).sum(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def negative_sampling(edge_index, num_neg_samples, num_nodes):\n",
    "    # Generate random node pairs that are not connected\n",
    "    neg_edges = set()\n",
    "    existing_edges = set([(edge_index[0, i].item(), edge_index[1, i].item()) for i in range(edge_index.size(1))])\n",
    "    while len(neg_edges) < num_neg_samples:\n",
    "        u = random.randint(0, num_nodes - 1)\n",
    "        v = random.randint(0, num_nodes - 1)\n",
    "        if u != v and (u, v) not in existing_edges and (v, u) not in existing_edges:\n",
    "            neg_edges.add((u, v))\n",
    "    neg_edges = torch.tensor(list(neg_edges), dtype=torch.long).t()\n",
    "    return neg_edges\n",
    "\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(data.x, data.edge_index)\n",
    "    \n",
    "    # Positive edges\n",
    "    pos_edge = data.train_edges.t()\n",
    "    pos_pred = model.decode(z, pos_edge)\n",
    "    pos_label = torch.ones(pos_pred.size(0))\n",
    "    \n",
    "    # Negative edges: Sample equal number of non-edges\n",
    "    num_neg = pos_pred.size(0)\n",
    "    neg_edges = negative_sampling(data.edge_index, num_neg, data.num_nodes)\n",
    "    neg_pred = model.decode(z, neg_edges)\n",
    "    neg_label = torch.zeros(neg_pred.size(0))\n",
    "    \n",
    "    # Combine\n",
    "    pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "    labels = torch.cat([pos_label, neg_label], dim=0)\n",
    "    \n",
    "    loss = criterion(pred, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(data.x, data.edge_index)\n",
    "        \n",
    "        # Positive test edges\n",
    "        pos_edge = data.test_edges.t()\n",
    "        pos_pred = model.decode(z, pos_edge).cpu().numpy()\n",
    "        pos_label = np.ones(pos_pred.shape[0])\n",
    "        \n",
    "        # Negative test edges\n",
    "        neg_edge = data.test_neg_edges.t()\n",
    "        neg_pred = model.decode(z, neg_edge).cpu().numpy()\n",
    "        neg_label = np.zeros(neg_pred.shape[0])\n",
    "        \n",
    "        # Combine\n",
    "        preds = np.concatenate([pos_pred, neg_pred])\n",
    "        labels = np.concatenate([pos_label, neg_label])\n",
    "        \n",
    "        auc = roc_auc_score(labels, preds)\n",
    "        ap = average_precision_score(labels, preds)\n",
    "        \n",
    "    return auc, ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.6854, AUC=0.6526, AP=0.6462\n",
      "Epoch 10: Loss=0.6866, AUC=0.6472, AP=0.6405\n",
      "Epoch 20: Loss=0.6898, AUC=0.6348, AP=0.6326\n",
      "Epoch 30: Loss=0.6924, AUC=0.6279, AP=0.6371\n",
      "Epoch 40: Loss=0.7015, AUC=0.6378, AP=0.6452\n",
      "Epoch 50: Loss=0.6899, AUC=0.6551, AP=0.6485\n",
      "Epoch 60: Loss=0.6935, AUC=0.6417, AP=0.6409\n",
      "Epoch 70: Loss=0.6891, AUC=0.6402, AP=0.6333\n",
      "Epoch 80: Loss=0.6916, AUC=0.6294, AP=0.6349\n",
      "Epoch 90: Loss=0.6956, AUC=0.6215, AP=0.6302\n",
      "Epoch 100: Loss=0.6911, AUC=0.6202, AP=0.6290\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "num_features = data.num_features\n",
    "hidden_dim = 64\n",
    "model = GNN15Layer(num_features, hidden_dim)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, data, optimizer, criterion)\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        auc, ap = test(model, data)\n",
    "        print(f\"Epoch {epoch}: Loss={loss:.4f}, AUC={auc:.4f}, AP={ap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'gnn15layer_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'gnn15layer_model.pth')\n",
    "print(\"Model saved as 'gnn15layer_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new model instance\n",
    "loaded_model = GNN15Layer(num_features, hidden_dim)\n",
    "loaded_model.load_state_dict(torch.load('gnn15layer_model.pth'))\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.2.105:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.2.105 - - [25/Nov/2024 13:13:22] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.2.105 - - [25/Nov/2024 13:13:22] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [25/Nov/2024 13:13:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Nov/2024 13:13:25] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "from threading import Thread\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = GNN15Layer(num_features, hidden_dim)\n",
    "loaded_model.load_state_dict(torch.load('gnn15layer_model.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Precompute node embeddings\n",
    "with torch.no_grad():\n",
    "    z = loaded_model(data.x, data.edge_index)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    Expects JSON with 'node1' and 'node2' as integers.\n",
    "    Example:\n",
    "    {\n",
    "        \"node1\": 0,\n",
    "        \"node2\": 1\n",
    "    }\n",
    "    \"\"\"\n",
    "    data_json = request.get_json()\n",
    "    node1 = data_json.get('node1')\n",
    "    node2 = data_json.get('node2')\n",
    "    \n",
    "    num_nodes = data.num_nodes\n",
    "    if node1 is None or node2 is None:\n",
    "        return jsonify({\"error\": \"Please provide 'node1' and 'node2' in the JSON payload.\"}), 400\n",
    "    if not (0 <= node1 < num_nodes) or not (0 <= node2 < num_nodes):\n",
    "        return jsonify({\"error\": f\"node indices must be between 0 and {num_nodes -1}\"}), 400\n",
    "    \n",
    "    edge_pair = torch.tensor([[node1, node2]], dtype=torch.long).t()\n",
    "    with torch.no_grad():\n",
    "        score = loaded_model.decode(z, edge_pair).item()\n",
    "    \n",
    "    prediction = {\n",
    "        \"node1\": node1,\n",
    "        \"node2\": node2,\n",
    "        \"edge_probability\": score\n",
    "    }\n",
    "    \n",
    "    return jsonify(prediction)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return '''\n",
    "    <h1>GNN Edge Prediction</h1>\n",
    "    <p>Use the /predict endpoint with a JSON payload containing \"node1\" and \"node2\".</p>\n",
    "    <p>Example payload:</p>\n",
    "    <pre>\n",
    "    {\n",
    "        \"node1\": 0,\n",
    "        \"node2\": 1\n",
    "    }\n",
    "    </pre>\n",
    "    '''\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "# Run Flask in a separate thread\n",
    "flask_thread = Thread(target=run_flask)\n",
    "flask_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
